---
title: "Entrada 05 ‚Äî Pr√°ctica 5: Validaci√≥n y Selecci√≥n de Modelos"
date: 2025-08-26
---

# üéØ Validaci√≥n Cruzada y Selecci√≥n de Modelos

## Contexto
Implementaci√≥n de t√©cnicas de validaci√≥n cruzada comparando algoritmos de clasificaci√≥n para predecir el √©xito acad√©mico estudiantil.

## Objetivos
- Implementar diferentes estrategias de validaci√≥n cruzada (KFold vs StratifiedKFold)
- Comparar el rendimiento de m√∫ltiples algoritmos de clasificaci√≥n
- Optimizar hiperpar√°metros usando GridSearchCV y RandomizedSearchCV
- Analizar la importancia de caracter√≠sticas para la explicabilidad del modelo

## Actividades (con tiempos estimados)
1. Configuraci√≥n del entorno y carga de librer√≠as ‚Äî 10 min
2. Exploraci√≥n del dataset de √©xito acad√©mico estudiantil ‚Äî 15 min
3. Implementaci√≥n de validaci√≥n cruzada KFold vs StratifiedKFold ‚Äî 25 min
4. Comparaci√≥n de modelos (Regresi√≥n Log√≠stica, Ridge, Random Forest) ‚Äî 30 min
5. Optimizaci√≥n de hiperpar√°metros ‚Äî 20 min
6. An√°lisis de explicabilidad e importancia de caracter√≠sticas ‚Äî 20 min

## Desarrollo
La pr√°ctica se centr√≥ en predecir el √©xito acad√©mico de estudiantes utilizando diferentes algoritmos de machine learning. Se trabaj√≥ con datos de 4424 estudiantes que inclu√≠an informaci√≥n acad√©mica, demogr√°fica y socioecon√≥mica.

El principal desaf√≠o fue el desbalance en los datos: solo el 56% de estudiantes se graduaba, mientras que el 29% abandonaba y el 15% segu√≠a matriculado. Para manejar este problema, se compararon dos t√©cnicas de validaci√≥n cruzada. La t√©cnica StratifiedKFold, que mantiene la proporci√≥n de clases en cada divisi√≥n de datos, demostr√≥ ser m√°s estable y confiable que el m√©todo tradicional.

El Random Forest arroj√≥ el mejor rendimiento con 76.6% de precisi√≥n, superando a la Regresi√≥n Log√≠stica y al Ridge Classifier. Al optimizar sus par√°metros, se logr√≥ mejorar su precisi√≥n a 77.8%.

El an√°lisis revel√≥ que las notas del segundo semestre son el factor m√°s importante para predecir el √©xito acad√©mico, seguido de las notas de admisi√≥n y el rendimiento del primer semestre.

Este enfoque permiti√≥ no solo identificar el mejor modelo predictivo, sino tambi√©n entender qu√© variables influyen m√°s en el √©xito acad√©mico de los estudiantes.

## Evidencias
<img width="863" height="528" alt="image" src="https://github.com/user-attachments/assets/526a3966-d134-4458-a6ce-411df8acaf5b" />

COMPARACI√ìN DE ESTABILIDAD:
     StratifiedKFold es M√ÅS ESTABLE (menor variabilidad)
     Recomendaci√≥n: Usar StratifiedKFold para este dataset

<img width="1189" height="589" alt="image" src="https://github.com/user-attachments/assets/eec59bcb-8434-4dcf-9743-4c6748c8a9cd" />

AN√ÅLISIS DE ESTABILIDAD:
     Logistic Regression: MUY ESTABLE (std: 0.0061)
     Ridge Classifier: MUY ESTABLE (std: 0.0032)
     Random Forest: MUY ESTABLE (std: 0.0064)

<img width="999" height="299" alt="image" src="https://github.com/user-attachments/assets/5ab2cd89-6a0f-43a8-8043-50740057d988" />

¬øCu√°ndo usar cada m√©todo?
    GridSearchCV cuando tienes pocos hiperpar√°metros y mucho tiempo de c√≥mputo.
    RandomizedSearchCV cuando tienes muchos hiperpar√°metros o poco tiempo limitado.
    Pipeline + SearchCV siempre previene data leaking autom√°ticamente.
    cross_val_score en el resultado final valida que la optimizaci√≥n no caus√≥ overfitting.

<img width="989" height="790" alt="image" src="https://github.com/user-attachments/assets/4c37f1e4-eef6-4597-b691-410e9adcee70" />

IMPORTANCIA POR CATEGOR√çAS:
Factores acad√©micos: 0.6443
Factores demogr√°ficos: 0.0499
Factores econ√≥micos: 0.0769

<img width="2472" height="1190" alt="image" src="https://github.com/user-attachments/assets/f45d2a52-761c-4f04-8b79-45e59b6f876b" />

ESTAD√çSTICAS DE LOS √ÅRBOLES:
Profundidad promedio (primeros 5 √°rboles): 21.2
N√∫mero promedio de nodos (primeros 5): 1139.0

DIVERSIDAD EN EL RANDOM FOREST:
El poder del Random Forest viene de la diversidad de sus √°rboles:
- Cada √°rbol ve una muestra diferente de datos (bootstrap)
- Cada split considera solo un subconjunto aleatorio de caracter√≠sticas
- La predicci√≥n final es el voto mayoritario de todos los √°rboles
Usando datos sin escalar para √°rboles individuales

## Dejo aqu√≠ el enlace al Google Colab donde est√° el an√°lisis completo: [PR√ÅCTICA 5](https://colab.research.google.com/drive/1Gj7JAXMHdowOcMFGTdt4rauMzbKdlYhH?usp=sharing)

## Reflexi√≥n
Lo m√°s desafiante: Entender las diferencias entre las estrategias de validaci√≥n cruzada y cu√°ndo aplicar cada una.

Lo m√°s valioso: Comprender que la optimizaci√≥n de hiperpar√°metros puede mejorar significativamente el rendimiento del modelo (de 76.58% a 77.83% en accuracy).

Aprendizaje clave: La validaci√≥n cruzada adem√°s de ser una t√©cnica de evaluaci√≥n, tambi√©n es una herramienta para entender la estabilidad y confiabilidad de nuestros modelos.

Pr√≥ximos pasos: Aplicar estas t√©cnicas a problemas de desbalance de clases m√°s extremos.
