---
title: "Entrada 13 ‚Äî Pr√°ctica 13: Fine-tuning de Transformers para Clasificaci√≥n Ofensiva"
date: 2025-11-04
---

# üòÄ An√°lisis de Sentimiento en Noticias Financieras usando Transformers

## Contexto
Implementaci√≥n de un modelo de clasificaci√≥n de sentimiento para noticias financieras utilizando el dataset zeroshot/twitter-financial-news-sentiment y el modelo BERT. El objetivo fue clasificar tweets financieros en tres categor√≠as: Bearish (0), Bullish (1) y Neutral (2).

## Objetivos
- Cargar y explorar un dataset de sentimiento financiero en ingl√©s.
- Preprocesar los datos y adaptarlos a un modelo Transformer (BERT).
- Entrenar y evaluar un clasificador de sentimiento utilizando la biblioteca transformers de Hugging Face.
- Analizar el rendimiento del modelo y reflexionar sobre su aplicabilidad en contextos financieros.

## Actividades (con tiempos estimados)
1. Configuraci√≥n del entorno e instalaci√≥n de bibliotecas (10 min).
2. Carga y exploraci√≥n del dataset (15 min).
3. Preprocesamiento y tokenizaci√≥n de los textos (20 min).
4. Entrenamiento y evaluaci√≥n del modelo BERT (45 min).
5. An√°lisis de resultados y reflexi√≥n (20 min).

## Desarrollo
Se utiliz√≥ el dataset zeroshot/twitter-financial-news-sentiment, que contiene tweets financieros etiquetados en tres categor√≠as de sentimiento. El dataset se dividi√≥ en entrenamiento (9,543 ejemplos) y validaci√≥n (2,388 ejemplos).

## Evidencias

0.  $BYND - JPMorgan reels in expectations on Beyo...      0

1.  $CCL $RCL - Nomura points to bookings weakness...      0
2.  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0
3.  $ESS: BTIG Research cuts to Neutral https://t....      0
4.  $FNKO - Funko slides after Piper Jaffray PT cu...      0
label
2.    6178
1.    1923
0.    1442

<img width="540" height="394" alt="image" src="https://github.com/user-attachments/assets/cfc47022-592f-4e62-a2ba-7afb893355c8" />

- ¬øC√≥mo es la distribuci√≥n de longitudes? ¬øQu√© implica para el truncation del tokenizer? La distribuci√≥n muestra que la mayor√≠a de textos tienen entre 5-20 tokens, con muy pocos superando 25 tokens. Esto confirma que un max_length de 128 es m√°s que suficiente y que incluso podr√≠a disminuirse y funcionar.
- ¬øLas clases est√°n balanceadas? ¬øC√≥mo afectar√° esto a las m√©tricas y al entrenamiento? Las clases est√°n desbalanceadas: Clase 2 (Neutral) = 6,178 (65%), Clase 1 (Bullish) = 1,923 (20%), Clase 0 (Bearish) = 1,442 (15%). Por este desbalance, el modelo tiende a favorecer a la clase mayoritaria.

<img width="471" height="311" alt="image" src="https://github.com/user-attachments/assets/27b5604b-c48f-49ec-85f4-2f2b980bf19e" />

Top n-grams para clase 0:
co: 737
https co: 735
https: 735
to: 383
the: 321
in: 267
of: 233
on: 224
as: 175
after: 171

Top n-grams para clase 1:
co: 852
https: 842
https co: 842
to: 492
on: 387
the: 349
in: 324
up: 269
stock: 258
at: 215

Top n-grams para clase 2:
co: 3559
https: 3518
https co: 3518
the: 1892
to: 1787
of: 1255
in: 1058
for: 882
on: 762
and: 760

<img width="636" height="350" alt="image" src="https://github.com/user-attachments/assets/45fcf054-4af7-433b-ad8a-6ca0f8673517" />

- ¬øQu√© n-grams son m√°s frecuentes por clase? ¬øTe sorprenden?
  - Clase 0 (Bearish): "after", "cut", "down" - t√©rminos negativos esperados
  - Clase 1 (Bullish): "up", "stock", "gain" - t√©rminos positivos claros
  - Clase 2 (Neutral): vocabulario general como "the", "to", "of"
- ¬øQu√© sesgos/ruido ves en las nubes de palabras? "https" y "co" dominan todas las clases, sugiriendo que URLs/tickers son ruido que deber√≠a limpiarse.

<img width="617" height="451" alt="image" src="https://github.com/user-attachments/assets/4523ca96-1bd8-4e2d-b298-40cfa323a361" />

<img width="617" height="451" alt="image" src="https://github.com/user-attachments/assets/b5ae4832-8bd3-4260-94af-15b4e4cf3280" />

- ¬øHay separabilidad en PCA/UMAP? Si no, ¬øpor qu√©? ¬øDatos solapados, ruido, features?
  - PCA revela cierta estructura pero con √°reas de mezcla
  - UMAP muestra un solapamiento significativo
  - El solapamiento sugiere que el contexto y relaciones sem√°nticas complejas son importantes.
- ¬øLos vecinos de Word2Vec reflejan sem√°ntica financiera? No reflejan sem√°ntica financiera.

              precision    recall  f1-score   support

           0       0.59      0.64      0.61       288
           1       0.72      0.73      0.72       385
           2       0.88      0.86      0.87      1236

    accuracy                           0.80      1909
   macro avg       0.73      0.74      0.74      1909
weighted avg       0.81      0.80      0.80      1909

<img width="392" height="316" alt="image" src="https://github.com/user-attachments/assets/78cb888b-5bd7-4353-9db8-14727add7346" />

- ¬øEn qu√© clases falla m√°s el baseline? ¬øPor qu√©?
  - Clase 0 (Bearish): F1 m√°s bajo (0.61) - clase minoritaria m√°s dif√≠cil
  - Clase 1 (Bullish): Performance media (0.72)
  - Clase 2 (Neutral): Mejor performance (0.87) - beneficio del desbalance
- ¬øQu√© hiperpar√°metros probaste y c√≥mo cambiaron los resultados?
  - class_weight='balanced' fue acertado dado el desbalance
  - ngram_range=(1,2) captur√≥ bigramas importantes como "price target", "stock up"
  - max_features=10000 no sobrecarga el modelo

Epoch	Training Loss	Validation Loss	Accuracy	F1

1	0.476500	0.403554	0.862232	0.809617

2	0.262600	0.388149	0.871661	0.826117

3	0.149000	0.469289	0.870613	0.827613

- ¬øCu√°nto mejora el Transformer al baseline? ¬øD√≥nde empeora?
  - Accuracy: 87.1% (+7 puntos vs baseline)
  - Macro F1: 82.8% (+9.3 puntos vs baseline)
  - Mejora consistente en todas las m√©tricas
- ¬øQu√© costo de entrenamiento observaste (tiempo/VRAM)? Tiempo de ~12 minutos

<img width="576" height="455" alt="image" src="https://github.com/user-attachments/assets/6017dd0f-2d57-4679-af6c-216f72b4b2c5" />

- ¬øCu√°l m√©todo elegir√≠as para producci√≥n y por qu√©? FinBERT.
  - FinBERT entiende contexto financiero espec√≠fico
  - Mejor manejo de lenguaje financiero t√©cnico
  - Superior discriminaci√≥n entre Bullish/Bearish
- ¬øQu√© siguientes pasos intentar√≠as (data cleaning, RAG, ajuste de clases)? El primer paso urgente ser√≠a una limpieza de datos, eliminando URLs, menciones, s√≠mbolos de trading.

## Dejo aqu√≠ el enlace al Google Colab donde est√° el an√°lisis completo: [PR√ÅCTICA 13](https://colab.research.google.com/drive/1Ff3za3Mgi-Oz7XhtuTgldWH0KRjDFjrg?usp=sharing)

## Reflexi√≥n
Lo m√°s desafiante: Ajustar el modelo BERT para un dominio espec√≠fico como las noticias financieras, ya que uso t√©rminos t√©cnicos.

Lo m√°s valioso: Poder aplicar un modelo complejo como BERT a un problema real de clasificaci√≥n de sentimiento con la ayuda de la biblioteca transformers.

Aprendizaje clave: Los modelos preentrenados como BERT son extremadamente vers√°tiles y pueden adaptarse a dominios espec√≠ficos con relativamente pocos datos.

Pr√≥ximos pasos: Experimentar con fine-tuning en datasets m√°s grandes o en otros idiomas.
