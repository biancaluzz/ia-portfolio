---
title: "Entrada 07 â€” PrÃ¡ctica 7: De PerceptrÃ³n a Redes Neuronales"
date: 2025-09-16
---

# ğŸ§  Del PerceptrÃ³n a las Redes Neuronales: Descifrando los LÃ­mites y Potencial del Aprendizaje Profundo

## Contexto
ImplementaciÃ³n de un perceptrÃ³n (unidad bÃ¡sica de una red neuronal) para resolver compuertas lÃ³gicas, para lograr entender cÃ³mo funciona un clasificador lineal y visualizar cÃ³mo aprende a separar diferentes datos.

## Objetivos
- Crear un perceptrÃ³n desde cero que pueda resolver AND y OR
- Ver grÃ¡ficamente cÃ³mo el perceptrÃ³n traza una lÃ­nea para separar los datos
. Entender cÃ³mo los pesos y el sesgo afectan las decisiones del modelo
- Descubrir quÃ© problemas puede y no puede resolver un perceptrÃ³n simple

## Actividades (con tiempos estimados)
1. PreparaciÃ³n del entorno - Definir las funciones del perceptrÃ³n (10 min)
2. Resolver AND - Encontrar pesos que funcionen y visualizar (20 min)
3. Resolver OR - Ajustar los parÃ¡metros para OR y visualizar (20 min)
4. Comparar resultados - Analizar diferencias y limitaciones (30 min)

## Desarrollo
Se implementÃ³ un perceptrÃ³n de manera manual, probando diferentes combinaciones de pesos y sesgo hasta encontrar las que resolvÃ­an perfectamente las compuertas AND y OR. Para cada compuerta:
- AND: Produce salida 1 solo cuando AMBAS entradas son 1
- OR: Produce salida 1 cuando AL MENOS UNA entrada es 1

Se encontrÃ³ que con pesos de 0.5 para ambas entradas, solo era necesario ajustar el sesgo:
- AND: Sesgo = -0.7 (comportamiento mÃ¡s estricto)
- OR: Sesgo = -0.2 (comportamiento mÃ¡s permisivo)

Ambos modelos alcanzaron 100% de precisiÃ³n, clasificando correctamente las cuatro combinaciones posibles de entradas (00, 01, 10, 11).

## Evidencias
1ï¸âƒ£ PROBLEMA AND: Solo verdadero cuando AMBAS entradas son 1

x1 | x2 | AND esperado

 0 |  0 |      0

 0 |  1 |      0

 1 |  0 |      0

 1 |  1 |      1

Probando AND con pesos: w1=0.5, w2=0.5, bias=-0.7
  - 0,0 â†’ 0 (esperado 0) âœ…
  - 0,1 â†’ 0 (esperado 0) âœ…
  - 1,0 â†’ 0 (esperado 0) âœ…
  - 1,1 â†’ 1 (esperado 1) âœ…

  <img width="707" height="556" alt="image" src="https://github.com/user-attachments/assets/05d82b0d-d0ad-432a-b009-3084537feba5" />

ğŸ” InterpretaciÃ³n: Los puntos ROJOS (â—‹) son clase 0, los AZULES (â– ) son clase 1
   La lÃ­nea VERDE separa las clases.

ğŸ’¡ RecordÃ¡: Un perceptrÃ³n es la ecuaciÃ³n de una lÃ­nea: y = wâ‚xâ‚ + wâ‚‚xâ‚‚ + b

2ï¸âƒ£ PROBLEMA OR: Verdadero cuando AL MENOS UNA entrada es 1

x1 | x2 | OR esperado

 0 |  0 |      0

 0 |  1 |      1

 1 |  0 |      1

 1 |  1 |      1

Probando OR con pesos: w1=0.5, w2=0.5, bias=-0.2
  - 0,0 â†’ 0 (esperado 0) âœ…
  - 0,1 â†’ 1 (esperado 1) âœ…
  - 1,0 â†’ 1 (esperado 1) âœ…
  - 1,1 â†’ 1 (esperado 1) âœ…

  <img width="707" height="556" alt="image" src="https://github.com/user-attachments/assets/8b1ae4b4-12d0-4347-81b1-a9e585a7ea67" />


3ï¸âƒ£ PROBLEMA NOT: Inversor simple

x | NOT esperado

0 |      1

1 |      0

Probando NOT con peso: w1=-1, bias=0.5
  - 0 â†’ 1 (esperado 1) âœ…
  - 1 â†’ 0 (esperado 0) âœ…

ğŸ‰ Â¡NOT tambiÃ©n funciona! El perceptrÃ³n es genial...

<img width="707" height="402" alt="image" src="https://github.com/user-attachments/assets/115289da-3d7d-44f9-aa24-2c101ef18b99" />

ğŸ” El umbral estÃ¡ en x = 0.50
   - Si x < 0.50 â†’ salida 1 (azul)
   - Si x > 0.50 â†’ salida 0 (rojo)

4ï¸âƒ£ PROBLEMA XOR: Verdadero solo cuando las entradas son DIFERENTES

x1 | x2 | XOR esperado

 0 |  0 |      0

 0 |  1 |      1

 1 |  0 |      1

 1 |  1 |      0

ğŸ¤” Intentemos resolver XOR...

  Intento 1: w1=1, w2=1, bias=-0.5
    - 0,0 â†’ 0 (esperado 0) âœ…
    - 0,1 â†’ 1 (esperado 1) âœ…
    - 1,0 â†’ 1 (esperado 1) âœ…
    - 1,1 â†’ 1 (esperado 0) âŒ
    - Aciertos: 3/4 (75%)

  Intento 2: w1=1, w2=1, bias=-1.5
    - 0,0 â†’ 0 (esperado 0) âœ…
    - 0,1 â†’ 0 (esperado 1) âŒ
    - 1,0 â†’ 0 (esperado 1) âŒ
    - 1,1 â†’ 1 (esperado 0) âŒ
    - Aciertos: 1/4 (25%)

  Intento 3: w1=0.5, w2=0.5, bias=-0.1
    - 0,0 â†’ 0 (esperado 0) âœ…
    - 0,1 â†’ 1 (esperado 1) âœ…
    - 1,0 â†’ 1 (esperado 1) âœ…
    - 1,1 â†’ 1 (esperado 0) âŒ
    - Aciertos: 3/4 (75%)

  Intento 4: w1=1, w2=-1, bias=0.5
    - 0,0 â†’ 1 (esperado 0) âŒ
    - 0,1 â†’ 0 (esperado 1) âŒ
    - 1,0 â†’ 1 (esperado 1) âœ…
    - 1,1 â†’ 1 (esperado 0) âŒ
    - Aciertos: 1/4 (25%)

ğŸ’¥ RESULTADO: Â¡NingÃºn perceptrÃ³n simple puede resolver XOR!
   - Mejor intento: 3/4 = 75%
   - ğŸ¤¯ Â¡Necesitamos algo mÃ¡s poderoso!

<img width="1189" height="985" alt="image" src="https://github.com/user-attachments/assets/ac819753-7aaa-46e4-8691-326b42be62c8" />

ğŸ” ANÃLISIS VISUAL:
   - ğŸ”µâ–  Puntos azules (cuadrados) deben estar de UN lado de la lÃ­nea
   - ğŸ”´â—‹ Puntos rojos (cÃ­rculos) deben estar del OTRO lado
   - ğŸ’¥ Â¡Es IMPOSIBLE dibujar una lÃ­nea recta que los separe perfectamente!
   - ğŸ§  Por eso necesitamos REDES MULTICAPA (mÃ¡s de una lÃ­nea)

ğŸ¯ MLP resuelve XOR:

x1 | x2 | esperado | predicciÃ³n | âœ“

 0 |  0 |    0     |     0      | âœ“

 0 |  1 |    1     |     0      | âœ—

 1 |  0 |    1     |     0      | âœ—

 1 |  1 |    0     |     0      | âœ“
- Accuracy: 50.0%
- ğŸ’¡ Â¡La red multicapa SÃ puede resolver XOR!

ğŸ¨ Visualizando arquitectura MLP para XOR:

<img width="1389" height="789" alt="image" src="https://github.com/user-attachments/assets/bafbb172-112a-4693-aae2-7f65bbb61625" />

- ğŸ“Š Capa 1: 2 â†’ 4 = 12 parÃ¡metros
- ğŸ“Š Capa 2: 4 â†’ 1 = 5 parÃ¡metros
- ğŸ¯ Total de parÃ¡metros: 17
- ğŸ§  Â¿Por quÃ© tantos parÃ¡metros? Cada conexiÃ³n tiene un peso + bias por neurona

<img width="1489" height="590" alt="image" src="https://github.com/user-attachments/assets/1d52f751-9379-4548-9353-6fa0ee7e7ab2" />

ğŸ” ANÃLISIS VISUAL:
   - ğŸ”´ Zonas ROJAS = predicciÃ³n 0 (clase 0)
   - ğŸ”µ Zonas AZULES = predicciÃ³n 1 (clase 1)
   - ğŸ“ PerceptrÃ³n: Solo puede crear lÃ­nea recta â†’ falla en XOR
   - ğŸŒŠ MLP: Puede crear superficie curva â†’ Â¡resuelve XOR!

ğŸ“Š Resultados MLP en dataset real:
  - Training Accuracy: 100.0%
  - Test Accuracy: 90.3%
  - Arquitectura: 20 â†’ (64, 32) â†’ 2

ğŸ¯ Resultados TensorFlow:
  - Training Accuracy: 100.0%
  - Test Accuracy: 94.0%
  - ParÃ¡metros totales: 3,457

<img width="1189" height="390" alt="image" src="https://github.com/user-attachments/assets/6aaaff74-14a0-4a46-b0c3-9b0ccac627b4" />


ğŸ¯ PyTorch Lightning model created!
- Input features: 20
- Parameters: 3,490

ğŸ¯ Resultados: [{'test_loss': 0.17256857454776764, 'test_acc': 0.9200000166893005}]

<img width="1463" height="390" alt="image" src="https://github.com/user-attachments/assets/50b1ecd8-ff76-4f5b-a572-5f3f98440164" />

ğŸ“ˆ ANÃLISIS DE MATRICES DE CONFUSIÃ“N:
- âœ… Diagonal principal (TN + TP) = predicciones correctas
- âŒ Diagonal secundaria (FP + FN) = errores

----------------------------------------------------------------------------
### Preguntas de ReflexiÃ³n

1. **Â¿Por quÃ© AND, OR y NOT funcionaron pero XOR no?**

Una lÃ­nea recta en un plano puede separar los casos positivos de los negativos de AND, OR y NOT, pero no de XOR. Esto se debe a que, sin importar dÃ³nde se coloque la recta, siempre se obtendrÃ¡ algÃºn valor incorrecto, como se observa en los grÃ¡ficos. Los puntos (0,1) y (1,0), que son los casos positivos, se encuentran entre los casos (0,0) y (1,1), lo que provoca que siempre haya al menos un caso predicho incorrectamente si se intenta predecir los casos positivos.


2. **Â¿CuÃ¡l es la diferencia clave entre los pesos de AND vs OR?**

La diferencia es que el AND necesita un umbral mÃ¡s alto para activarse, ya que solamente se activarÃ¡ cuando ambos son positivos. Mientras que en el OR, mientras que al menos uno de los 2 sea positivo, ya se activa.


3. **Â¿QuÃ© otros problemas del mundo real serÃ­an como XOR?**

- Prendido o Apagado
- Hombre o Mujer
- Vivo o Muerto
- Enfermo o Sano


4. **Â¿Por quÃ© sklearn MLP puede resolver XOR pero un perceptrÃ³n no?**

Debido a que MLP permite representar una curva, sobre el plano, la cual captura a los puntos (0,1) y (1,0), sin tener que predecir incorrectamente (1,1) y (0,0). Gracias a las multi capas.


5. **Â¿CuÃ¡l es la principal diferencia entre TensorFlow/Keras y sklearn MLP?**

Un TensorFlow solo puede crear una Ãºnica lÃ­nea de decisiÃ³n, mientras que un MLP con capas ocultas puede crear superficies de decisiÃ³n.


6. **Â¿Por quÃ© TensorFlow usa epochs y batch_size mientras sklearn MLP no?**

TensorFlow procesa los datos en lotes (batches) y mÃºltiples iteraciones (epochs), mientras que sklearn MLP generalmente procesa todos los datos a la vez en cada iteraciÃ³n.


7. **Â¿CuÃ¡ndo usarÃ­as sigmoid vs relu como funciÃ³n de activaciÃ³n?**

Sigmoid se usa en la capa de salida para clasificaciÃ³n binaria, mientras que ReLU se usa en capas ocultas.


8. **Â¿QuÃ© ventaja tiene PyTorch Lightning sobre TensorFlow puro?**

PyTorch Lightning reduce el cÃ³digo boilerplate, organizando el flujo de entrenamiento, validaciÃ³n y test, lo que facilita experimentaciÃ³n rÃ¡pida y hace que el cÃ³digo sea mÃ¡s limpio y mantenible.


9. **Â¿Por quÃ© PyTorch Lightning separa training_step y test_step?**

Porque el comportamiento durante entrenamiento y evaluaciÃ³n es distinto:
En training_step se calcula la pÃ©rdida y se aplican gradientes (backprop).
En test_step o validation_step solo se evalÃºa el modelo sin modificar los pesos.


10. **Â¿CuÃ¡l framework elegirÃ­as para cada escenario?**

- Prototipo rÃ¡pido: SkLearn MLP
- Modelo en producciÃ³n: TensorFlow
- InvestigaciÃ³n avanzada: PyTorch


11. **Â¿Por quÃ© el error dimensional mat1 and mat2 shapes cannot be multiplied es comÃºn en PyTorch?**

Sucede cuando las dimensiones de entrada del dataset no coinciden con la primera capa del modelo. Siempre hay que asegurar que input_size de la primera capa lineal coincida con el nÃºmero de features de tus datos.


12. **Â¿QuÃ© significa el parÃ¡metro deterministic=True en PyTorch Lightning Trainer?**

Garantiza reproducibilidad entre ejecuciones, evitando que resultados cambien por operaciones de CUDA u optimizadores.


13. **Â¿Por quÃ© TensorFlow muestra curvas de loss y val_loss durante entrenamiento?**

loss indica cÃ³mo aprende el modelo en entrenamiento y val_loss en validaciÃ³n. Comparando ambas se puede detectar overfitting: si loss baja y val_loss sube, el modelo se estÃ¡ ajustando demasiado a los datos de entrenamiento.


14. **Â¿CuÃ¡l es la diferencia entre trainer.test() y trainer.predict() en PyTorch Lightning?**

- trainer.test(): devuelve mÃ©tricas y calcula pÃ©rdidas sobre un dataset de test.
- trainer.predict(): devuelve solo las predicciones sin calcular mÃ©tricas.


15. **Â¿Por quÃ© sklearn MLP es mÃ¡s fÃ¡cil pero menos flexible?**

Es mÃ¡s simple porque maneja automÃ¡ticamente entrenamiento, optimizaciÃ³n y evaluaciÃ³n, pero pierdes flexibilidad para:
- Customizar capas y forward pass
- Controlar ciclos de entrenamiento
- Integrar callbacks complejos o mÃ©todos avanzados de regularizaciÃ³n

----------------------------------------------------------------------------

## Dejo aquÃ­ el enlace al Google Colab donde estÃ¡ el anÃ¡lisis completo: [PRÃCTICA 7](https://colab.research.google.com/drive/12YFP6ude6fcXIn5AkmLUSZHjNy2I4IyE?usp=sharing)

## ReflexiÃ³n
Lo mÃ¡s desafiante: Pasar de pensar en lÃ­neas rectas a superficies. Ver que ningÃºn ajuste logra el 100% de precisiÃ³n.

Lo mÃ¡s valioso: La comparaciÃ³n prÃ¡ctica entre diferentes frameworks (sklearn, TensorFlow/Keras y PyTorch Lightning) para entender sus aplicaciones especÃ­ficas.

Aprendizaje clave: un perceptrÃ³n funciona bien para separar linealmente (AND, OR), pero su verdadero potencial se ve cuando se combinan para formar redes neuronales.

PrÃ³ximos pasos: Profundizar en arquitecturas de redes neuronales mÃ¡s complejas.
