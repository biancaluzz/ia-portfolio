---
title: "Entrada 10 ‚Äî Pr√°ctica 10: Data Augmentation Avanzado & Explicabilidad"
date: 2025-10-14
---

# üå∏ Data Augmentation Avanzado & Explicabilidad: Clasificaci√≥n de Flores

## Contexto
Implementaci√≥n de pipelines de data augmentation avanzado y t√©cnicas de explicabilidad para mejorar la clasificaci√≥n de flores del dataset Oxford Flowers102 usando transfer learning con EfficientNet.

## Objetivos
- Implementar pipelines de data augmentation con Keras layers
- Aplicar transfer learning con EfficientNetB0 para clasificaci√≥n de 102 especies de flores
- Utilizar t√©cnicas de explicabilidad (Grad-CAM) para entender las decisiones del modelo
- Comparar el rendimiento con y sin data augmentation avanzado

## Actividades (con tiempos estimados)
1. Setup y carga del dataset Oxford Flowers102 (30 min)
2. Implementaci√≥n de pipelines de data augmentation (45 min)
3. Entrenamiento con transfer learning y fine-tuning (60 min)
4. An√°lisis de explicabilidad con Grad-CAM (45 min)

## Desarrollo
Se implementaron dos pipelines principales para el dataset Oxford Flowers102:
- Pipeline Baseline: Preprocesamiento b√°sico con normalizaci√≥n EfficientNet
- Pipeline Avanzado: Data augmentation con transformaciones geom√©tricas (flip, rotation, zoom, translation) y fotom√©tricas (brightness, contrast)

Se utiliz√≥ EfficientNetB0 con fine-tuning en las capas finales, logrando clasificaci√≥n multiclase para las 102 especies de flores. Las t√©cnicas de Grad-CAM permitieron visualizar qu√© regiones de las im√°genes eran m√°s relevantes para las predicciones del modelo.

## Evidencias

Dataset oxford_flowers102 downloaded and prepared to /root/tensorflow_datasets/oxford_flowers102/2.1.1. Subsequent calls will reuse this data.
‚úÖ Dataset descargado:
   Train: 1020 im√°genes
   Test: 6149 im√°genes
   Clases: 102

‚úÖ Datasets preparados:
   Train subset: 5000
   Test subset: 1000
   Rango de p√≠xeles: [0, 255] (antes de normalizaci√≥n)

üé® VISUALIZACI√ìN: Data Augmentation
   Nota: Visualizaci√≥n usa im√°genes [0, 255] ANTES de normalizaci√≥n
<img width="1456" height="1475" alt="image" src="https://github.com/user-attachments/assets/7c81e44a-33ff-4294-a08c-17886e9bcbc3" />

## üéØ Reflexi√≥n Final:

- Data Augmentation: El aumento de datos ayuda a prevenir overfitting y mejora la generalizaci√≥n, especialmente importante en datasets peque√±os como el de flores.

- GradCAM: Permite verificar si el modelo est√° aprendiendo caracter√≠sticas relevantes de las flores (p√©talos, centro) en lugar de patrones irrelevantes.

- Errores del Modelo: Al analizar errores con GradCAM, podemos identificar si el modelo se confunde por fondos similares o caracter√≠sticas compartidas entre especies.

- Aplicaci√≥n Pr√°ctica: En una app de identificaci√≥n de flores, la explicabilidad es crucial para generar confianza en los usuarios y validar que el modelo funciona correctamente.

- Mejoras: Fine-tuning del modelo base, m√°s datos de entrenamiento, y experimentar con diferentes t√©cnicas de aumento de datos podr√≠an mejorar a√∫n m√°s el rendimiento.

## Dejo aqu√≠ el enlace al Google Colab donde est√° el an√°lisis completo y la implementaci√≥n del modelo propio: [PR√ÅCTICA 10](https://colab.research.google.com/drive/1eAiS-PlZpinHKu7_l5rb-JBoa9zBULPS?usp=sharing)

##Reflexi√≥n
Lo m√°s desafiante: Crear el modelo propio desde 0.

Lo m√°s valioso: Ver c√≥mo Grad-CAM revela que el modelo realmente aprende caracter√≠sticas espec√≠ficas en lugar de patrones superficiales.

Aprendizaje clave: El data augmentation bien dise√±ado puede ser m√°s efectivo que arquitecturas complejas para mejorar generalizaci√≥n en dominios espec√≠ficos.

Pr√≥ximos pasos: Experimentar con t√©cnicas de auto-augmentation y aplicar estas metodolog√≠as a otros datasets de im√°genes especializadas.
