---
title: "Entrada 13 ‚Äî Pr√°ctica 13: Fine-tuning de Transformers para Clasificaci√≥n Ofensiva"
date: 2025-11-04
---

# üòÄ An√°lisis de Sentimiento en Noticias Financieras usando Transformers

## Contexto
Implementaci√≥n de un modelo de clasificaci√≥n de sentimiento para noticias financieras utilizando el dataset zeroshot/twitter-financial-news-sentiment y el modelo BERT. El objetivo fue clasificar tweets financieros en tres categor√≠as: Bearish (0), Bullish (1) y Neutral (2).

## Objetivos
- Cargar y explorar un dataset de sentimiento financiero en ingl√©s.
- Preprocesar los datos y adaptarlos a un modelo Transformer (BERT).
- Entrenar y evaluar un clasificador de sentimiento utilizando la biblioteca transformers de Hugging Face.
- Analizar el rendimiento del modelo y reflexionar sobre su aplicabilidad en contextos financieros.

## Actividades (con tiempos estimados)
1. Configuraci√≥n del entorno e instalaci√≥n de bibliotecas (10 min).
2. Carga y exploraci√≥n del dataset (15 min).
3. Preprocesamiento y tokenizaci√≥n de los textos (20 min).
4. Entrenamiento y evaluaci√≥n del modelo BERT (45 min).
5. An√°lisis de resultados y reflexi√≥n (20 min).

## Desarrollo
Se utiliz√≥ el dataset zeroshot/twitter-financial-news-sentiment, que contiene tweets financieros etiquetados en tres categor√≠as de sentimiento. El dataset se dividi√≥ en entrenamiento (9,543 ejemplos) y validaci√≥n (2,388 ejemplos).

## Evidencias

0  $BYND - JPMorgan reels in expectations on Beyo...      0
1  $CCL $RCL - Nomura points to bookings weakness...      0
2  $CX - Cemex cut at Credit Suisse, J.P. Morgan ...      0
3  $ESS: BTIG Research cuts to Neutral https://t....      0
4  $FNKO - Funko slides after Piper Jaffray PT cu...      0
label
2    6178
1    1923
0    1442
Name: count, dtype: int64

<img width="1456" height="1475" alt="image" src="https://github.com/user-attachments/assets/7c81e44a-33ff-4294-a08c-17886e9bcbc3" />

## Dejo aqu√≠ el enlace al Google Colab donde est√° el an√°lisis completo: [PR√ÅCTICA 13](https://colab.research.google.com/drive/1Ff3za3Mgi-Oz7XhtuTgldWH0KRjDFjrg?usp=sharing)

## Reflexi√≥n
Lo m√°s desafiante: Ajustar el modelo BERT para un dominio espec√≠fico como las noticias financieras, ya que uso t√©rminos t√©cnicos.

Lo m√°s valioso: Poder aplicar un modelo complejo como BERT a un problema real de clasificaci√≥n de sentimiento con la ayuda de la biblioteca transformers.

Aprendizaje clave: Los modelos preentrenados como BERT son extremadamente vers√°tiles y pueden adaptarse a dominios espec√≠ficos con relativamente pocos datos.

Pr√≥ximos pasos: Experimentar con fine-tuning en datasets m√°s grandes o en otros idiomas.
