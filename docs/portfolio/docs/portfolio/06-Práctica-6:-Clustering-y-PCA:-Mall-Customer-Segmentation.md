---
title: "Entrada 06 â€” PrÃ¡ctica 6: Clustering y PCA: Mall Customer Segmentation"
date: 2025-09-09
---

# Entrada 06 â€” PrÃ¡ctica 6: Clustering y PCA: Mall Customer Segmentation

## Contexto
ImplementaciÃ³n de tÃ©cnicas de clustering para segmentar clientes de centros comerciales basÃ¡ndose en informaciÃ³n demogrÃ¡fica y de comportamiento de compra.

## Objetivos
- Identificar 3-5 segmentos distintos de clientes usando K-Means
- Aplicar tÃ©cnicas de normalizaciÃ³n (MinMax, Standard, Robust) y comparar resultados
- Utilizar PCA para reducciÃ³n de dimensionalidad y visualizaciÃ³n
- Comparar PCA con mÃ©todos de selecciÃ³n de features
- Interpretar resultados desde una perspectiva de negocio

## Actividades (con tiempos estimados)
1. ConfiguraciÃ³n del entorno y carga de librerÃ­as â€” 10 min
2. ExploraciÃ³n del Mall Customer Segmentation Dataset â€” 20 min
3. Preprocesamiento y normalizaciÃ³n de datos â€” 20 min
4. ImplementaciÃ³n de K-Means clustering â€” 25 min
5. AplicaciÃ³n de PCA y reducciÃ³n dimensional â€” 20 min
6. AnÃ¡lisis de segmentos e interpretaciÃ³n de negocio â€” 25 min

## Desarrollo
La prÃ¡ctica se centrÃ³ en segmentar clientes de centros comerciales utilizando tÃ©cnicas de clustering no supervisado. Se trabajÃ³ con datos de 200 clientes que incluÃ­an informaciÃ³n demogrÃ¡fica (edad, gÃ©nero) y de comportamiento (ingresos anuales, puntuaciÃ³n de gastos).

El principal desafÃ­o fue determinar el nÃºmero Ã³ptimo de clusters y seleccionar las tÃ©cnicas de preprocesamiento mÃ¡s adecuadas. Se compararon tres mÃ©todos de normalizaciÃ³n (MinMax, Standard y Robust) y se encontrÃ³ que MinMaxScaler proporcionaba los mejores resultados para este dataset.

El mÃ©todo del codo sugiriÃ³ 5 clusters como nÃºmero Ã³ptimo, pero tras validaciÃ³n con mÃ©tricas de silueta, se determinÃ³ que 4 clusters proporcionaban una segmentaciÃ³n mÃ¡s adecuada.

El anÃ¡lisis PCA permitiÃ³ reducir la dimensionalidad de 4 a 2 componentes principales que capturaban el 82.3% de la varianza, facilitando la visualizaciÃ³n de los segmentos.

## Evidencias

<img width="1489" height="495" alt="image" src="https://github.com/user-attachments/assets/dd22d7aa-1d07-4bf4-9cda-e918e405c36e" />

<img width="1790" height="495" alt="image" src="https://github.com/user-attachments/assets/0e8c5f1a-e618-4cdc-961a-e5a13f292f01" />

<img width="675" height="590" alt="image" src="https://github.com/user-attachments/assets/cc76ecb0-8d7e-444d-ae52-d4037fdc6d70" />

INSIGHTS PRELIMINARES - COMPLETE:

COMPLETE BASÃNDOTE EN TUS OBSERVACIONES:
   Variable con mayor variabilidad: El annual income posee la mayor STD CON 26,26K$, es la que posee mayor variabilidad
   - Â¿Existe correlaciÃ³n fuerte entre alguna variable? Ninguna posee una correlaciÃ³n fuerte, pero la que posee la mayor correlaciÃ³n es la edad con el spending score, a mayor edad peor spending score, con un coeficiente de 0.327
   - Â¿QuÃ© variable tiene mÃ¡s outliers? El annual income es el unico con outliers, un total de 2 (1%)
   - Â¿Los hombres y mujeres tienen patrones diferentes? Son similares, aunque en promedio parece que las mujeres ganen menos, y tengan un mejor spending score. La desvianciÃ³n estandar del spending score, es mayor en los hombres, indicando que varian mas sus valores
   - Â¿QuÃ© insight es mÃ¡s relevante para el anÃ¡lisis? El diagrama de dispersiÃ³n, de la relaciÃ³n entre el annual income, y spending score muestra una posible segmentaciÃ³n al observar las agrupaciones que ocurren en los datos.
   - Â¿QuÃ© 2 variables serÃ¡n mÃ¡s importantes para clustering? Por annual income, y spending score. Por las observaciones previamente explicadas

PREPARÃNDOSE PARA CLUSTERING:
   - Â¿QuÃ© relaciÃ³n entre Income y Spending Score observas? Parecen ser adecuadas para el clustering debido a las agrupaciones, observadas en el grafico de dispersiÃ³n
   - Â¿Puedes imaginar grupos naturales de clientes? Imaginamos 5 grupos a partir de la observaciÃ³n del grafico de dispersiÃ³n, aquellos que ganan poco, y gastan mucho, los que ganan poco y gastan poco, los que ganan en el promedio y gastan lo promedio (donde se concentran la mayoria de los valores), los que ganan mucho y gastan mucho, y por ultimo los que ganan mucho y gastan poco.

ANÃLISIS DE LAS ESTADÃSTICAS - COMPLETA:
   - Â¿QuÃ© variable tiene el rango mÃ¡s amplio? Annual Income (k$)
   - Â¿CuÃ¡l es la distribuciÃ³n de gÃ©nero en el dataset? 40% hombres 60% mujeres
   - Â¿QuÃ© variable muestra mayor variabilidad (std)? Annual Income (k$)
   - Â¿Los clientes son jÃ³venes o mayores en promedio? Son mas jovenes (38.8 aÃ±os promedio) en comparaciÃ³n con los limites del rango
   - Â¿El income promedio sugiere quÃ© clase social? Media ($60.56k promedio), ya que hay gente que gana mucho y gasta poco, y viceversa.
   - Â¿Por quÃ© la normalizaciÃ³n serÃ¡ crÃ­tica aca? Por los diferentes rangos de las variables.

LISTO PARA DATA PREPARATION con 5 features

<img width="1583" height="397" alt="image" src="https://github.com/user-attachments/assets/55821591-ba1b-40c0-83a8-5b9aeba310c6" />

<img width="1589" height="396" alt="image" src="https://github.com/user-attachments/assets/1ad688c2-c8a4-4bf3-accc-4371ecb21f2f" />

QUICK TEST: Impacto en Clustering (K=4)
     - MinMax: Silhouette Score = 0.364
     - Standard: Silhouette Score = 0.332
     - Robust: Silhouette Score = 0.298

GANADOR: MinMax (Score: 0.364)

Â¿CuÃ¡l mÃ©todo necesitas para obtener las etiquetas de cluster (no las distancias)?

El metodo .labels()

Â¿QuÃ© significa un silhouette score mÃ¡s alto vs mÃ¡s bajo?

Un score mas bajo es menos confiable, mayor es mas confiable, debido a que estan mas definidos los clusters (mas separados unos de otros y se ve una clara divisiÃ³n)

DECISIÃ“N FINAL DEL SCALER:

COMPLETE TU ANÃLISIS:
   - Mejor scaler segÃºn silhouette: MinMax
   - Â¿Por quÃ© crees que funcionÃ³ mejor? Funciono mejor debido a que los datos no poseen un rango demasiado extenso, no hay datos atipicos que puedan romper el escalamiento, por lo cual es una buena forma de escalar los valores para la segmentaciÃ³n.
   - Â¿AlgÃºn scaler tuvo problemas obvios? Ninguno mostro problemas obvios, ya que todos poseen valores entre 0 y 1.

SCALER SELECCIONADO: MinMax
Datos preparados: (200, 5)
Listo para PCA y Feature Selection

<img width="1490" height="590" alt="image" src="https://github.com/user-attachments/assets/a93aaa37-c425-4f62-a931-8d4215c41a78" />

<img width="1190" height="790" alt="image" src="https://github.com/user-attachments/assets/f2135f4d-38e1-4867-ab3e-2811b8ef6711" />

ğŸ’¡ INTERPRETACIÃ“N DE NEGOCIO:
   - ğŸ¯ PC1 parece representar: Diferencia por genero, basandonos en el loading, se puede ver que son los valores que mas impactan
   - ğŸ¯ PC2 parece representar: Contraste entre edad y nivel de gasto, por las mismas razones.
   - ğŸ“Š Los clusters visibles sugieren: Existen grupos de clientes separados principalmente por gÃ©nero, y dentro de cada gÃ©nero se diferencian por edad y comportamiento de gasto

ğŸ“Š COMPARACIÃ“N DE MÃ‰TODOS:
   - ğŸ Baseline (todas): 0.364
   - ğŸ”„ Forward Selection: 0.573
   - ğŸ”™ Backward Elimination: 0.573
   - ğŸ“ PCA (2D): 0.686

ğŸ† GANADOR: PCA (2D) con score = 0.686

ğŸ” ANÃLISIS:
   - PCA (2D): 0.686 (+88.3% vs baseline)
   - Forward Selection: 0.573 (+57.5% vs baseline)
   - Backward Elimination: 0.573 (+57.5% vs baseline)
   - Baseline (todas): 0.364 (+0.0% vs baseline)

<img width="1189" height="589" alt="image" src="https://github.com/user-attachments/assets/d6e821dc-1f8d-45ca-a4a4-0706b720047a" />

ğŸ¯ ANÃLISIS DE RESULTADOS:

ğŸ” FEATURES SELECCIONADAS POR CADA MÃ‰TODO:
   - ğŸ”„ Forward Selection: [np.str_('Spending Score (1-100)'), np.str_('Genre_Female'), np.str_('Genre_Male')]
   - ğŸ”™ Backward Elimination: [np.str_('Spending Score (1-100)'), np.str_('Genre_Female'), np.str_('Genre_Male')]

ğŸ¤ COINCIDENCIAS:
   - Forward âˆ© Backward: [np.str_('Spending Score (1-100)'), np.str_('Genre_Female'), np.str_('Genre_Male')]
   - Â¿Seleccionaron las mismas features? SÃ­

â“ PREGUNTAS DE ANÃLISIS (completa):
   - ğŸ’¡ MÃ©todo con mejor score: PCA (2D) con score = 0.686
   - ğŸ“Š Â¿Forward y Backward seleccionaron exactamente las mismas features? Si, Spending Score, Genre_Female y Genre_Male
   - ğŸ¤” Â¿PCA con 2 componentes es competitivo? Si, es el mejor y supera a Backward y Forward
   - ğŸ¯ Â¿AlgÃºn mÃ©todo superÃ³ el threshold de 0.5? Si PCA 2D, Backward y Forward lo superaron.
   - ğŸ“ˆ Â¿La reducciÃ³n de dimensionalidad mejorÃ³ el clustering? Reducir de 5 a 2 si mejoro el clustering, porque hace mas visible la divisiÃ³n de grupos, con las 5 dimensiones el PC4 Y PC5 eran solo ruido que mas que aportar molestaba.

<img width="1489" height="590" alt="image" src="https://github.com/user-attachments/assets/dcdd894d-b434-4885-a7f6-439103781a36" />

<img width="1490" height="990" alt="image" src="https://github.com/user-attachments/assets/71a806d2-6e0a-431e-9efa-4dcb158c5b6c" />

----------------------------------------------------------------------------
### MetodologÃ­a CRISP-DM:

#### Â¿QuÃ© fase fue mÃ¡s desafiante y por quÃ©?
La fase mÃ¡s complicada fue Data Preparation, ya que se tuvo que aplicar mÃºltiples tÃ©cnicas de escalado y reducciÃ³n de dimensionalidad. A partir de ello, decidir cuÃ¡l era mejor para el conjunto de datos para garantizar que los reusltados fuerna Ã³ptimos para el clustering.

#### Â¿CÃ³mo el entendimiento del negocio influyÃ³ en tus decisiones tÃ©cnicas?
Sabiendo que se trata de un centro comercial que busca segmentar clientes para mejorar las estrategias de marketing, se sabÃ­a que Annual Income y Spending Score iban a ser crÃ­ticas.


----------------------------------------------------------------------------
### Data Preparation:

#### Â¿QuÃ© scaler funcionÃ³ mejor y por quÃ©?
El MinMax Scaler funcionÃ³ mejor en este caso especÃ­fico, obteniendo un Silhouette Score de 0.364 (vs. 0.332 de Standard y 0.298 de Robust) para K=4. Esto se debe a la naturaleza de los datos:
1. Los datos de Annual Income y Spending Score estÃ¡n acotados en rangos similares
2. No presentan outliers extremos.
3. MinMax asegura que todas las variables tengan el mismo peso (misma escala), evitando que una variable domine por su magnitud (ej: ingreso vs. score).

#### Â¿PCA o Feature Selection fue mÃ¡s efectivo para tu caso?
PCA fue mÃ¡s efectivo porque permitiÃ³ reducir la dimensionalidad manteniendo la mayor varianza posible, lo que mejorÃ³ la visualizaciÃ³n y el rendimiento del clustering.

#### Â¿CÃ³mo balanceaste interpretabilidad vs performance?
Se utilizÃ³ PCA para mejorar la performance del modelo, pero se complementÃ³ con anÃ¡lisis de las componentes principales para entender quÃ© variables originales contribuÃ­an mÃ¡s a cada cluster.


----------------------------------------------------------------------------
### Clustering:

#### Â¿El Elbow Method y Silhouette coincidieron en el K Ã³ptimo?
SÃ­, ambos mÃ©todos sugirieron que el nÃºmero Ã³ptimo de clusters era 5.

#### Â¿Los clusters encontrados coinciden con la intuiciÃ³n de negocio?
SÃ­, los clusters representaron segmentos claros como clientes de alto ingreso y gasto, clientes de bajo ingreso y gasto, y clientes de comportamiento medio.

#### Â¿QuÃ© harÃ­as diferente si fueras a repetir el anÃ¡lisis?
Tal vez probar con otros algoritmos de clustering para poder comparar resultados.


----------------------------------------------------------------------------
### AplicaciÃ³n PrÃ¡ctica:

#### Â¿CÃ³mo presentarÃ­as estos resultados en un contexto empresarial?
Para presentar resultados siempre conviene tener visualizaciones claras con grÃ¡ficos, acompaÃ±ado con un informe que resuma los segmentos encontrados, descripciÃ³n y recomendaciones.

#### Â¿QuÃ© valor aportan estas segmentaciones?
- Optimizar campaÃ±as de marketing dirigidas a grupos especÃ­ficos.
- Asignar recursos de manera mÃ¡s eficiente.
- Mejorar la experiencia del cliente con ofertas personalizadas.
- Incrementar la retenciÃ³n y el gasto promedio por cliente.

#### Â¿QuÃ© limitaciones tiene este anÃ¡lisis?
La data utilizada contiene 200 registros y podrÃ­a no ser representativa de todos. Las variables utilizadas son bÃ¡sicas, estarÃ­a bueno incluir atributos de comportamiento.

----------------------------------------------------------------------------

## Dejo aquÃ­ el enlace al Google Colab donde estÃ¡ el anÃ¡lisis completo: [PRÃCTICA 6](https://colab.research.google.com/drive/1bFpBO1SDSvFfT15RNVKFCL6-Xx1zpwVF?usp=sharing)

## ReflexiÃ³n
Lo mÃ¡s desafiante: Determinar el nÃºmero Ã³ptimo de clusters, ya que el mÃ©todo del codo y el anÃ¡lisis de silueta sugerÃ­an diferentes nÃºmeros Ã³ptimos.

Lo mÃ¡s valioso: Comprender cÃ³mo las diferentes tÃ©cnicas de normalizaciÃ³n afectan significativamente los resultados del clustering, y cÃ³mo PCA no solo ayuda en la visualizaciÃ³n sino tambiÃ©n en la identificaciÃ³n de las caracterÃ­sticas mÃ¡s relevantes.

Aprendizaje clave: En clustering, la validaciÃ³n cualitativa (interpretaciÃ³n de negocio) es tan importante como las mÃ©tricas cuantitativas.

PrÃ³ximos pasos: Aplicar tÃ©cnicas de clustering mÃ¡s avanzadas, y explorar mÃ©todos de validaciÃ³n mÃ¡s sofisticados para problemas de segmentaciÃ³n de clientes.
