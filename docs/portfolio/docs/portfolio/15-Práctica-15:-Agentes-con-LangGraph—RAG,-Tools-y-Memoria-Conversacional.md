---
title: "Entrada 15 ‚Äî Agentes con LangGraph ‚Äî RAG, Tools y Memoria Conversacional"
date: 2025-11-18
---

# üëÆ‚Äç‚ôÄÔ∏è Agentes con LangGraph: Construyendo Asistentes con Memoria y RAG

## Contexto
Implementaci√≥n de un agente inteligente utilizando LangGraph, combinando herramientas de RAG, consulta de estado del sistema y memoria conversacional en un grafo de estado ejecutable.

## Objetivos
- Crear un grafo de estado con LangGraph para orquestar un agente conversacional
- Integrar herramientas de RAG para b√∫squeda en base de conocimiento
- Implementar memoria ligera mediante res√∫menes conversacionales
- Desarrollar una interfaz interactiva con Gradio para probar el agente

## Actividades (con tiempos estimados)
1. Setup inicial y Hello Agent (15 min)
2. Definici√≥n del estado del agente con memoria ligera (20 min)
3. Construcci√≥n del sistema RAG m√≠nimo (25 min)
4. Implementaci√≥n de tools adicionales (15 min)
5. Integraci√≥n de tool calling con LLM (30 min)
6. Desarrollo del grafo completo assistant ‚Üî tools (25 min)
7. Pruebas multi-turn y memoria (20 min)
8. Interfaz Gradio (15 min)

## Desarrollo
Se construy√≥ un agente completo que combina capacidades de reasoning con herramientas espec√≠ficas. El sistema utiliza:
- Grafo de estado: Nodos para assistant, tools y memory
- RAG personalizado: Base de conocimiento con informaci√≥n de la empresa
- Tools integradas: B√∫squeda sem√°ntica y consulta de estado del sistema
- Memoria conversacional: Res√∫menes peri√≥dicos para mantener contexto
- Interfaz interactiva: Chatbot con Gradio para pruebas en tiempo real

## Evidencias
- ¬øQu√© diferencia hay entre esto y hacer llm.invoke("prompt") directo?  La diferencia es que con LangGraph no le est√°s tirando un prompt suelto al modelo: est√°s moviendo un estado que va pasando de nodo en nodo. Cada nodo agarra ese estado, lo modifica y lo vuelve a pasar. En cambio, cuando hac√©s llm.invoke("prompt"), no hay recorrido, no hay memoria ni pasos: solo mand√°s texto y recib√≠s texto
- ¬øD√≥nde ves expl√≠citamente que hay un estado que viaja por el grafo? Se ve explicitamente cuando:
  - Lo defin√≠s como AgentState.
  - Lo pas√°s al grafo con graph.invoke(initial_state).
  - Cada nodo lo recibe como state en def assistant_node(state).

- ¬øQu√© ventaja tiene guardar un summary en vez de todo el historial? Guardar un resumen en lugar de todo el historial hace que el agente sea m√°s r√°pido y eficiente, porque no necesita procesar cada mensaje cada vez. Adem√°s, permite concentrarse en lo importante y mantener el contexto de la conversaci√≥n sin todo el ruido de los mensajes antiguos, haciendo que la charla sea m√°s clara y fluida.
- ¬øQu√© informaci√≥n NO deber√≠as guardar en ese resumen por temas de privacidad? Por motivos de privacidad, nunca se debe incluir datos sensibles de las personas, como nombres completos, direcciones, contrase√±as o informaci√≥n financiera. El resumen debe ser √∫til para el agente y seguro, solo con lo necesario para continuar la¬†conversaci√≥n.

- ¬øQu√© cambiar√≠as si el corpus fuera mucho m√°s grande? Si el corpus fuera mucho m√°s grande, habr√≠a que pensar en estrategias para no sobrecargar al modelo ni la b√∫squeda, probablemente deber√≠a usar un √≠ndice m√°s eficiente, limitar√≠a la cantidad de resultados o resumir√≠a los documentos antes de pasarlos como contexto.
- ¬øQu√© pasar√≠a si devolv√©s textos muy largos en el context? Devolver textos demasiado largos tambi√©n puede ser un problema, porque el LLM tiene un l√≠mite de tokens y puede perder foco en lo importante, adem√°s, se vuelve m√°s lento y caro procesar tanta informaci√≥n. Por eso conviene que la tool entregue solo lo relevante y conciso para que el agente pueda usarlo efectivamente.

- ¬øQu√© problema tendr√≠a esta tool si la us√°s en producci√≥n real? Si la us√°ramos en producci√≥n real, estas tools tendr√≠an varios problemas: por un lado, FAKE_ORDERS es solo un diccionario en memoria, as√≠ que no refleja datos reales ni concurrentes, y cualquier acceso simult√°neo podr√≠a generar inconsistencias. Adem√°s, no hay validaci√≥n ni control de errores sofisticado, y exponer directamente funciones como get_order_status o get_utc_time podr√≠a abrir vulnerabilidades si se reciben inputs maliciosos.
- ¬øC√≥mo la har√≠as m√°s segura / robusta? Para hacerlas m√°s seguras y robustas habr√≠a que conectarlas a una base de datos real con control de acceso, validar y sanear los inputs, manejar errores de manera confiable, y limitar la informaci√≥n sensible que se devuelve, asegurando que solo se entregue lo necesario para cada usuario.

- ¬øD√≥nde est√° ahora el ‚Äúreasoning‚Äù? ¬øEn qu√© nodo? El reasoning ahora ocurre principalmente en el nodo assistant. Es ah√≠ donde el LLM analiza el historial de mensajes y decide si puede responder directamente o si necesita llamar a alguna tool. El nodo de tools simplemente ejecuta lo que se le pide; no decide ni razona por s√≠ mismo.
- ¬øC√≥mo cambiar√≠a el dise√±o si tuvieras 10 tools en vez de 2-3? Si tuvieras 10 tools en lugar de 2 o 3, el dise√±o deber√≠a ser m√°s organizado: probablemente convendr√≠a tener un sistema de routing m√°s sofisticado para decidir cu√°l tool llamar, o categorizar las tools por tipo de tarea para no sobrecargar al LLM con demasiadas opciones a la vez. Esto ayudar√≠a a mantener eficiente la toma de decisiones y evitar confusiones en la elecci√≥n de herramientas.

### Respuesta 1: 
LangGraph es una plataforma/SDK para dise√±ar, ejecutar y monitorizar aplicaciones basadas en modelos de lenguaje mediante grafos de componentes. Permite componer pasos (prompts, llamadas a LLMs, embeddings, b√∫squedas en vectores, herramientas externas) de forma visual o por c√≥digo, gestionar versiones, hacer pruebas y observar el comportamiento en producci√≥n. En pocas palabras: facilita construir y coordinar pipelines de IA conversacional/LLM sin tener que ensamblar todo desde cero.

¬øQuieres que te muestre un ejemplo r√°pido o c√≥mo ser√≠a un peque√±o flujo?

### Respuesta 2: 
RAG = Retrieval-Augmented Generation. En pocas palabras: es una t√©cnica que combina un sistema de recuperaci√≥n (search/recall) con un generador de lenguaje (LLM) para que las respuestas se apoyen en documentos reales en lugar de solo en la memoria del modelo.

C√≥mo funciona (resumen):
- Se recibe la consulta del usuario.
- Un retriever (BM25 o retriever denso con embeddings) busca documentos relevantes en una colecci√≥n o vector DB.
- Se toman las top‚Äëk evidencias y se pasan al generador (un LLM) junto con la consulta.
- El LLM produce la respuesta condicionada en esas evidencias (y la consulta), lo que ayuda a fundamentar la salida.

Componentes t√≠picos:
- √çndice/colecci√≥n de documentos (base de conocimiento).
- Retriever (sparse o dense; a menudo embeddings + ANN).
- Reranker opcional.
- Generador/decoder (seq2seq LLM).
- Orquestaci√≥n y l√≥gica de fusi√≥n/aggregate (p. ej. RAG‚ÄëSequence, RAG‚ÄëToken, o enfoques como Fusion‚Äëin‚ÄëDecoder).

Ventajas:
- Reduce hallucinations al basar respuestas en evidencia externa.
- Permite respuestas con informaci√≥n actualizable sin reentrenar el modelo.
- Escalable para grandes colecciones.

Limitaciones y retos:
- Calidad depende de la recuperaci√≥n (si no recupera la evidencia correcta, la respuesta puede ser err√≥nea).
- Latencia y coste mayores (b√∫squeda + generaci√≥n).
- Requiere gesti√≥n de √≠ndices, filtrado y control de versiones de datos.
- Aun puede ‚Äúalucinar‚Äù combinando mal las evidencias o extrapolando.

Usos comunes:
- Sistemas de preguntas y respuestas sobre documentaci√≥n/FAQ.
- Asistentes con acceso a bases de conocimiento internas o datos actualizados.
- Soporte t√©cnico, legal, m√©dico (con cuidado y validaci√≥n).

Si quer√©s, te muestro un ejemplo corto en Python (LangChain/FAISS) o un diagrama del flujo. ¬øCu√°l prefer√≠s?

### Respuesta 3
√öltimo mensaje: human ‚Üí Us√° tu base de conocimiento y decime qu√© es RAG.
√öltimo mensaje: ai ‚Üí RAG = Retrieval-Augmented Generation. En pocas palabras: es una t√©cnica que combina b√∫squeda (recuperaci√≥n) de informaci√≥n relevante en una base de conocimientos con generaci√≥n de texto por un modelo de lenguaje, para que las respuestas est√©n fundamentadas en documentos y no solo en la memoria del modelo.

Concepto y por qu√© se usa
- Problema: los LLMs pueden olvidar hechos recientes o inventar (hallucinar) respuestas.
- Soluci√≥n RAG: antes de generar la respuesta, buscar fragmentos relevantes en una colecci√≥n (docs, FAQ, base interna, web), y dar esos fragmentos como contexto al modelo para que los use al generar la salida.

Componentes b√°sicos
1. Indexaci√≥n: preparar y almacenar documentos (texto, PDFs, bases) en una estructura indexable.
2. Representaci√≥n: convertir documentos y consultas a vectores (embeddings) o usar √≠ndices invertidos (BM25).
3. Recuperador (retriever): dado el input del usuario, devuelve los documentos o pasajes m√°s relevantes.
4. Re-ranker (opcional): ordena o filtra los resultados recuperados para mayor precisi√≥n.
5. Generador: un LLM que recibe la consulta y los pasajes recuperados (en el prompt) y genera la respuesta final.
6. Post-procesado: citar fuentes, limitar la longitud, verificar con reglas, etc.

Tipos de retrieval
- Sparse retrieval: b√∫squedas por t√©rminos (BM25).
- Dense retrieval: b√∫squeda por similitud de embeddings (FAISS, Milvus).
- H√≠brido: combina ambos para mejor cobertura.

Ventajas
- Respuestas m√°s precisas y actualizables sin reentrenar el modelo.
- Permite auditar y citar fuentes.
- Maneja conocimiento espec√≠fico de dominio o reciente.

Limitaciones y riesgos
- Calidad depende de la indexaci√≥n y de la capacidad del retriever.
- Latencia mayor (recuperaci√≥n + generaci√≥n).
- Si los pasajes contienen errores, el modelo puede propagar o mezclar informaci√≥n incorrecta.
- Manejo de contexto limitado por el tama√±o del prompt; hay que seleccionar bien los pasajes.

Buenas pr√°cticas
- Limitar y seleccionar pasajes relevantes (chunking y scoring).
- Incluir instrucciones en el prompt para usar o citar solo la informaci√≥n recuperada.
- Re-rankeado y verificaci√≥n de hechos cuando importa la exactitud.
- Actualizar el √≠ndice para mantener datos recientes.

Casos de uso
- Asistentes de atenci√≥n al cliente con base de conocimientos.
- Sistemas de preguntas y respuestas sobre documentaci√≥n t√©cnica.
- Chatbots legales/medicina (con verificaci√≥n y control humano).
- Res√∫menes y b√∫squeda sem√°ntica en grandes colecciones.

Si quer√©s, te muestro un flujo simple paso a paso o un ejemplo de prompt/arquitectura con herramientas comunes (FAISS, embeddings, LLM). ¬øQuer√©s eso?


- ¬øReconoc√©s cu√°ndo el agente est√° llamando rag_search vs get_order_status? Se puede ver claramente cu√°ndo el agente est√° llamando a rag_search o a get_order_status porque el LLM genera una tool call en su mensaje. Esa llamada indica que no est√° respondiendo directamente, sino que necesita ejecutar una herramienta para obtener informaci√≥n.
- ¬øQu√© tipo de prompts le dar√≠as al modelo para que use tools ‚Äúcon criterio‚Äù? Para que el modelo use las tools con criterio, conviene darle prompts claros que expliquen qu√© hace cada tool, cu√°ndo conviene usarla y qu√© tipo de respuesta se espera. De esta manera, el LLM puede decidir de forma m√°s inteligente si necesita recurrir a una tool o si puede responder directamente con lo que ya sabe.

- ¬øC√≥mo decidir√≠as cada cu√°nto actualizar el summary? Actualizar√≠a el summary cada cierto n√∫mero de turnos o cuando la conversaci√≥n haya cambiado de tema de manera significativa, de modo que refleje el contexto relevante sin ser redundante ni demasiado frecuente.
- ¬øQu√© tipo de info deber√≠as excluir del summary? En el resumen no incluir√≠a informaci√≥n sensible o privada de los usuarios, como datos personales, contrase√±as o detalles financieros; solo deber√≠a concentrarse en lo importante para que el agente recuerde el hilo de la conversaci√≥n y pueda dar respuestas coherentes.

<img width="1919" height="858" alt="image" src="https://github.com/user-attachments/assets/beae42e0-c078-4a7e-b297-e91b4b55fa21" />

### Mini-agente de Soporte con RAG + Tool de Estado
<img width="1919" height="861" alt="image" src="https://github.com/user-attachments/assets/184ce80d-d115-454c-9693-7315753ef39b" />


## Dejo aqu√≠ el enlace al Google Colab donde est√° el an√°lisis completo: [PR√ÅCTICA 15](https://colab.research.google.com/drive/1lyYC0JWZxmRKrGqxBWT21f-fCmAGBspF?usp=sharing)

## Reflexi√≥n
Lo m√°s desafiante: Entender el flujo del grafo de estado, especialmente la gesti√≥n del estado.

Lo m√°s valioso: Ver c√≥mo el agente decide autom√°ticamente cu√°ndo usar tools vs responder directo, demostrando reasoning pr√°ctico.

Aprendizaje clave: En lugar de un solo prompt, donde tengo que incluir manualmente todo el historial de la conversaci√≥n si quiero hacer un seguimiento, creas un grafo con diferentes nodos. Cada nodo es un paso especializado en un proceso.

Pr√≥ximos pasos: Explorar arquitecturas m√°s complejas con m√∫ltiples agentes.
